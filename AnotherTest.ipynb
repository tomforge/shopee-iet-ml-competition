{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.applications import inception_resnet_v2\n",
    "# from keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "from src.utils import printModelMetric, analyze\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomforge\\anaconda3\\envs\\aicv\\lib\\site-packages\\keras\\models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model1 = load_model(\"inception_v4_finetune_84.h5\")\n",
    "#model2 = load_model(\"inception_v3_finetune_828.h5\")\n",
    "#model3 = load_model(\"inception_v3_85_hinge.h5\")\n",
    "#model3 = load_model(\"inception_v4_difftop.h5\")\n",
    "model3 = load_model(\"inception_v4_hinge.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16111 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "TEST_DIR = 'TestImages'\n",
    "IMG_WIDTH, IMG_HEIGHT = 256, 256\n",
    "NUM_PREDICT = 16111\n",
    "\n",
    "# Need to apply the same data preprocessing\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "\n",
    "# Set no shuffle so the predictions follow file order\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3813 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "TEST_DIR = 'data/test'\n",
    "IMG_WIDTH, IMG_HEIGHT = 256, 256\n",
    "NUM_PREDICT = 3813\n",
    "\n",
    "# Need to apply the same data preprocessing\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "\n",
    "# Set no shuffle so the predictions follow file order\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 60s 500ms/step\n"
     ]
    }
   ],
   "source": [
    "results1 = model1.predict_generator(test_generator, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model(\"inception_v3_finetune_828.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 38s 316ms/step\n"
     ]
    }
   ],
   "source": [
    "results2 = model2.predict_generator(test_generator, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 59s 494ms/step\n"
     ]
    }
   ],
   "source": [
    "results3 = model3.predict_generator(test_generator, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = load_model(\"inception_v4_difftop_832.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 64s 534ms/step\n"
     ]
    }
   ],
   "source": [
    "results4 = model4.predict_generator(test_generator, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = np.argmax((results1 + results3)/2, axis=1)\n",
    "ensemble_w828 = np.argmax((results1 + results2 + results3)/3, axis=1)\n",
    "\n",
    "# womenPreds = np.argmax(womenRes, axis=1)\n",
    "# correctedWomenPreds = np.copy(womenPreds)\n",
    "# ensemble12 = np.argmax((results1 + results2)/2, axis=1)\n",
    "# ensemblewWomen = np.copy(ensemble12)\n",
    "# womenCat = [5, 7, 9, 11, 13, 15, 16]\n",
    "# womenMask = np.full_like(womenPreds, False, dtype=bool)\n",
    "# for i,v in enumerate(womenCat):\n",
    "#     # Get all the rows predicted as women tops\n",
    "#     if v != 16:\n",
    "#         womenMask = womenMask | (ensemblewWomen == v)\n",
    "#     # Update the women classifier labels to the correct ones\n",
    "#     correctedWomenPreds[womenPreds == i] = v\n",
    "# # Use women classfier values for women tops\n",
    "# ensemblewWomen[womenMask] = correctedWomenPreds[womenMask]\n",
    "# print(np.bincount(ensemblewWomen))\n",
    "# print(np.bincount(ensemble12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ensemble w hinge no difftop-----\n",
      "Label 0: Num images: 338; True pos: 336; False pos: 2\n",
      ">>> Rate truepos: 0.9940828402366864; Rate falsepos: 0.005917159763313609\n",
      ">>> Most frequently predicted as label 1 with 1 images.\n",
      "Label 1: Num images: 265; True pos: 265; False pos: 2\n",
      ">>> Rate truepos: 1.0; Rate falsepos: 0.00749063670411985\n",
      ">>> Most frequently predicted as label 0 with 0 images.\n",
      "Label 2: Num images: 192; True pos: 188; False pos: 3\n",
      ">>> Rate truepos: 0.9791666666666666; Rate falsepos: 0.015706806282722512\n",
      ">>> Most frequently predicted as label 3 with 1 images.\n",
      "Label 3: Num images: 191; True pos: 166; False pos: 13\n",
      ">>> Rate truepos: 0.8691099476439791; Rate falsepos: 0.07262569832402235\n",
      ">>> Most frequently predicted as label 4 with 10 images.\n",
      "Label 4: Num images: 197; True pos: 194; False pos: 15\n",
      ">>> Rate truepos: 0.9847715736040609; Rate falsepos: 0.07177033492822966\n",
      ">>> Most frequently predicted as label 0 with 1 images.\n",
      "Label 5: Num images: 211; True pos: 145; False pos: 36\n",
      ">>> Rate truepos: 0.6872037914691943; Rate falsepos: 0.19889502762430938\n",
      ">>> Most frequently predicted as label 13 with 23 images.\n",
      "Label 6: Num images: 310; True pos: 235; False pos: 23\n",
      ">>> Rate truepos: 0.7580645161290323; Rate falsepos: 0.08914728682170543\n",
      ">>> Most frequently predicted as label 10 with 67 images.\n",
      "Label 7: Num images: 318; True pos: 277; False pos: 105\n",
      ">>> Rate truepos: 0.8710691823899371; Rate falsepos: 0.27486910994764396\n",
      ">>> Most frequently predicted as label 15 with 12 images.\n",
      "Label 8: Num images: 144; True pos: 118; False pos: 16\n",
      ">>> Rate truepos: 0.8194444444444444; Rate falsepos: 0.11940298507462686\n",
      ">>> Most frequently predicted as label 14 with 16 images.\n",
      "Label 9: Num images: 228; True pos: 181; False pos: 48\n",
      ">>> Rate truepos: 0.793859649122807; Rate falsepos: 0.2096069868995633\n",
      ">>> Most frequently predicted as label 11 with 25 images.\n",
      "Label 10: Num images: 298; True pos: 259; False pos: 82\n",
      ">>> Rate truepos: 0.8691275167785235; Rate falsepos: 0.2404692082111437\n",
      ">>> Most frequently predicted as label 6 with 18 images.\n",
      "Label 11: Num images: 291; True pos: 204; False pos: 65\n",
      ">>> Rate truepos: 0.7010309278350515; Rate falsepos: 0.241635687732342\n",
      ">>> Most frequently predicted as label 7 with 27 images.\n",
      "Label 12: Num images: 182; True pos: 161; False pos: 31\n",
      ">>> Rate truepos: 0.8846153846153846; Rate falsepos: 0.16145833333333334\n",
      ">>> Most frequently predicted as label 10 with 9 images.\n",
      "Label 13: Num images: 161; True pos: 102; False pos: 57\n",
      ">>> Rate truepos: 0.6335403726708074; Rate falsepos: 0.3584905660377358\n",
      ">>> Most frequently predicted as label 7 with 18 images.\n",
      "Label 14: Num images: 168; True pos: 151; False pos: 23\n",
      ">>> Rate truepos: 0.8988095238095238; Rate falsepos: 0.13218390804597702\n",
      ">>> Most frequently predicted as label 8 with 9 images.\n",
      "Label 15: Num images: 129; True pos: 96; False pos: 23\n",
      ">>> Rate truepos: 0.7441860465116279; Rate falsepos: 0.19327731092436976\n",
      ">>> Most frequently predicted as label 7 with 23 images.\n",
      "Label 16: Num images: 81; True pos: 43; False pos: 39\n",
      ">>> Rate truepos: 0.5308641975308642; Rate falsepos: 0.47560975609756095\n",
      ">>> Most frequently predicted as label 11 with 13 images.\n",
      "Label 17: Num images: 109; True pos: 109; False pos: 0\n",
      ">>> Rate truepos: 1.0; Rate falsepos: 0.0\n",
      ">>> Most frequently predicted as label 0 with 0 images.\n",
      "Accuracy: 0.8471020194072908\n",
      "\n",
      "\n",
      "-----ensemble no hinge w difftop-----\n",
      "Label 0: Num images: 338; True pos: 336; False pos: 2\n",
      ">>> Rate truepos: 0.9940828402366864; Rate falsepos: 0.005917159763313609\n",
      ">>> Most frequently predicted as label 1 with 1 images.\n",
      "Label 1: Num images: 265; True pos: 265; False pos: 2\n",
      ">>> Rate truepos: 1.0; Rate falsepos: 0.00749063670411985\n",
      ">>> Most frequently predicted as label 0 with 0 images.\n",
      "Label 2: Num images: 192; True pos: 188; False pos: 3\n",
      ">>> Rate truepos: 0.9791666666666666; Rate falsepos: 0.015706806282722512\n",
      ">>> Most frequently predicted as label 3 with 1 images.\n",
      "Label 3: Num images: 191; True pos: 166; False pos: 13\n",
      ">>> Rate truepos: 0.8691099476439791; Rate falsepos: 0.07262569832402235\n",
      ">>> Most frequently predicted as label 4 with 10 images.\n",
      "Label 4: Num images: 197; True pos: 194; False pos: 15\n",
      ">>> Rate truepos: 0.9847715736040609; Rate falsepos: 0.07177033492822966\n",
      ">>> Most frequently predicted as label 0 with 1 images.\n",
      "Label 5: Num images: 211; True pos: 145; False pos: 36\n",
      ">>> Rate truepos: 0.6872037914691943; Rate falsepos: 0.19889502762430938\n",
      ">>> Most frequently predicted as label 13 with 23 images.\n",
      "Label 6: Num images: 310; True pos: 235; False pos: 23\n",
      ">>> Rate truepos: 0.7580645161290323; Rate falsepos: 0.08914728682170543\n",
      ">>> Most frequently predicted as label 10 with 67 images.\n",
      "Label 7: Num images: 318; True pos: 277; False pos: 105\n",
      ">>> Rate truepos: 0.8710691823899371; Rate falsepos: 0.27486910994764396\n",
      ">>> Most frequently predicted as label 15 with 12 images.\n",
      "Label 8: Num images: 144; True pos: 118; False pos: 16\n",
      ">>> Rate truepos: 0.8194444444444444; Rate falsepos: 0.11940298507462686\n",
      ">>> Most frequently predicted as label 14 with 16 images.\n",
      "Label 9: Num images: 228; True pos: 181; False pos: 48\n",
      ">>> Rate truepos: 0.793859649122807; Rate falsepos: 0.2096069868995633\n",
      ">>> Most frequently predicted as label 11 with 25 images.\n",
      "Label 10: Num images: 298; True pos: 259; False pos: 82\n",
      ">>> Rate truepos: 0.8691275167785235; Rate falsepos: 0.2404692082111437\n",
      ">>> Most frequently predicted as label 6 with 18 images.\n",
      "Label 11: Num images: 291; True pos: 204; False pos: 65\n",
      ">>> Rate truepos: 0.7010309278350515; Rate falsepos: 0.241635687732342\n",
      ">>> Most frequently predicted as label 7 with 27 images.\n",
      "Label 12: Num images: 182; True pos: 161; False pos: 31\n",
      ">>> Rate truepos: 0.8846153846153846; Rate falsepos: 0.16145833333333334\n",
      ">>> Most frequently predicted as label 10 with 9 images.\n",
      "Label 13: Num images: 161; True pos: 102; False pos: 57\n",
      ">>> Rate truepos: 0.6335403726708074; Rate falsepos: 0.3584905660377358\n",
      ">>> Most frequently predicted as label 7 with 18 images.\n",
      "Label 14: Num images: 168; True pos: 151; False pos: 23\n",
      ">>> Rate truepos: 0.8988095238095238; Rate falsepos: 0.13218390804597702\n",
      ">>> Most frequently predicted as label 8 with 9 images.\n",
      "Label 15: Num images: 129; True pos: 96; False pos: 23\n",
      ">>> Rate truepos: 0.7441860465116279; Rate falsepos: 0.19327731092436976\n",
      ">>> Most frequently predicted as label 7 with 23 images.\n",
      "Label 16: Num images: 81; True pos: 43; False pos: 39\n",
      ">>> Rate truepos: 0.5308641975308642; Rate falsepos: 0.47560975609756095\n",
      ">>> Most frequently predicted as label 11 with 13 images.\n",
      "Label 17: Num images: 109; True pos: 109; False pos: 0\n",
      ">>> Rate truepos: 1.0; Rate falsepos: 0.0\n",
      ">>> Most frequently predicted as label 0 with 0 images.\n",
      "Accuracy: 0.8471020194072908\n",
      "\n",
      "\n",
      "-----ensemble w hinge w difftop-----\n",
      "Label 0: Num images: 338; True pos: 336; False pos: 0\n",
      ">>> Rate truepos: 0.9940828402366864; Rate falsepos: 0.0\n",
      ">>> Most frequently predicted as label 1 with 1 images.\n",
      "Label 1: Num images: 265; True pos: 265; False pos: 2\n",
      ">>> Rate truepos: 1.0; Rate falsepos: 0.00749063670411985\n",
      ">>> Most frequently predicted as label 0 with 0 images.\n",
      "Label 2: Num images: 192; True pos: 188; False pos: 3\n",
      ">>> Rate truepos: 0.9791666666666666; Rate falsepos: 0.015706806282722512\n",
      ">>> Most frequently predicted as label 9 with 2 images.\n",
      "Label 3: Num images: 191; True pos: 169; False pos: 19\n",
      ">>> Rate truepos: 0.8848167539267016; Rate falsepos: 0.10106382978723404\n",
      ">>> Most frequently predicted as label 11 with 6 images.\n",
      "Label 4: Num images: 197; True pos: 195; False pos: 10\n",
      ">>> Rate truepos: 0.9898477157360406; Rate falsepos: 0.04878048780487805\n",
      ">>> Most frequently predicted as label 3 with 1 images.\n",
      "Label 5: Num images: 211; True pos: 145; False pos: 31\n",
      ">>> Rate truepos: 0.6872037914691943; Rate falsepos: 0.17613636363636365\n",
      ">>> Most frequently predicted as label 7 with 25 images.\n",
      "Label 6: Num images: 310; True pos: 236; False pos: 25\n",
      ">>> Rate truepos: 0.7612903225806451; Rate falsepos: 0.09578544061302682\n",
      ">>> Most frequently predicted as label 10 with 65 images.\n",
      "Label 7: Num images: 318; True pos: 274; False pos: 97\n",
      ">>> Rate truepos: 0.8616352201257862; Rate falsepos: 0.261455525606469\n",
      ">>> Most frequently predicted as label 15 with 15 images.\n",
      "Label 8: Num images: 144; True pos: 116; False pos: 15\n",
      ">>> Rate truepos: 0.8055555555555556; Rate falsepos: 0.11450381679389313\n",
      ">>> Most frequently predicted as label 14 with 16 images.\n",
      "Label 9: Num images: 228; True pos: 182; False pos: 50\n",
      ">>> Rate truepos: 0.7982456140350878; Rate falsepos: 0.21551724137931033\n",
      ">>> Most frequently predicted as label 11 with 26 images.\n",
      "Label 10: Num images: 298; True pos: 256; False pos: 83\n",
      ">>> Rate truepos: 0.8590604026845637; Rate falsepos: 0.2448377581120944\n",
      ">>> Most frequently predicted as label 6 with 22 images.\n",
      "Label 11: Num images: 291; True pos: 206; False pos: 66\n",
      ">>> Rate truepos: 0.7079037800687286; Rate falsepos: 0.2426470588235294\n",
      ">>> Most frequently predicted as label 9 with 28 images.\n",
      "Label 12: Num images: 182; True pos: 161; False pos: 33\n",
      ">>> Rate truepos: 0.8846153846153846; Rate falsepos: 0.17010309278350516\n",
      ">>> Most frequently predicted as label 10 with 10 images.\n",
      "Label 13: Num images: 161; True pos: 104; False pos: 41\n",
      ">>> Rate truepos: 0.6459627329192547; Rate falsepos: 0.2827586206896552\n",
      ">>> Most frequently predicted as label 5 with 16 images.\n",
      "Label 14: Num images: 168; True pos: 152; False pos: 22\n",
      ">>> Rate truepos: 0.9047619047619048; Rate falsepos: 0.12643678160919541\n",
      ">>> Most frequently predicted as label 8 with 7 images.\n",
      "Label 15: Num images: 129; True pos: 97; False pos: 30\n",
      ">>> Rate truepos: 0.751937984496124; Rate falsepos: 0.23622047244094488\n",
      ">>> Most frequently predicted as label 7 with 23 images.\n",
      "Label 16: Num images: 81; True pos: 53; False pos: 42\n",
      ">>> Rate truepos: 0.654320987654321; Rate falsepos: 0.4421052631578947\n",
      ">>> Most frequently predicted as label 11 with 9 images.\n",
      "Label 17: Num images: 109; True pos: 109; False pos: 0\n",
      ">>> Rate truepos: 1.0; Rate falsepos: 0.0\n",
      ">>> Most frequently predicted as label 0 with 0 images.\n",
      "Accuracy: 0.8507736690270129\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printModelMetric(analyze(pred_labels1), \"inception_v4_84\")\n",
    "# printModelMetric(analyze(pred_labels2), \"inception_v3_828\") \n",
    "# printModelMetric(analyze(ensemble12), \"inception_v4_84 + inception_v3_828 ensemble\")\n",
    "# printModelMetric(analyze(ensemblewWomen), \"Ensemble + women classifier\")\n",
    "#printModelMetric(analyze(np.argmax(results3, axis=1)), \"inception_v4_hinge\")\n",
    "ensemble123 = np.argmax((results1 + results2 + results3)/3, axis=1)\n",
    "printModelMetric(analyze(ensemble123), \"ensemble w hinge no difftop\")\n",
    "ensemble124 = np.argmax((results1 + results2 + results4)/3, axis=1)\n",
    "printModelMetric(analyze(ensemble123), \"ensemble no hinge w difftop\")\n",
    "ensemble1234 = np.argmax((results1 + results2 + results3 + results4)/4, axis=1)\n",
    "printModelMetric(analyze(ensemble1234), \"ensemble w hinge w difftop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image ids from the filenames (which are in order)\n",
    "ids = [int(f[10:-4]) for f in test_generator.filenames]\n",
    "# Create the csv for submission\n",
    "sub = pd.DataFrame({'id':ids, 'category':ensemble})\n",
    "sub = sub.sort_values(by=['id'])\n",
    "# Place id column first\n",
    "sub = sub[['id', 'category']]\n",
    "sub.to_csv('2semble_w_hinge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the csv for submission\n",
    "sub = pd.DataFrame({'id':ids, 'category':ensemble_w828})\n",
    "sub = sub.sort_values(by=['id'])\n",
    "# Place id column first\n",
    "sub = sub[['id', 'category']]\n",
    "sub.to_csv('3semble_w_hinge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
